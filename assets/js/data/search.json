[ { "title": "Learning rsync with ChatGPT", "url": "/posts/learning-rsync-with-chatgpt/", "categories": "education", "tags": "education, chatgpt, backups, linux", "date": "2022-12-13 21:15:00 -0500", "snippet": "OverviewAs people play around with ChatGPT, I’ve been seeing all sorts of reactions, and all sorts of things those people are trying. For me, one of the first places I gravitated to was to help me ...", "content": "OverviewAs people play around with ChatGPT, I’ve been seeing all sorts of reactions, and all sorts of things those people are trying. For me, one of the first places I gravitated to was to help me with some bash script. As I’ve dabbled in bash over the years, I’ve learned more and more little tricks. However, there were still some things I would get stuck on.At the moment, I’m revamping how I do Linux backups. One of the things I’d like to figure out “once and for all” is how to rsync my backups off my server and get them to my NAS. I thought: this is a good time to see if ChatGPT has some ideas!Tips on using ChatGPTOne of the really key elements of success, is to give it as much information as possible. If you just ask a superficial question, you’ll get a superficial answer. However, if you give it: machine names, user names, variable names, explain the logic that is needed - it will produce really high quality output. So, that is what I tried.Asking ChatGPT how to use rsync correctlyBelow is my copy/pasted transcript of what I asked, and what it responded with. This is primarily to show that if you give it deep details, it will create very high quality responses. This short conversation gave me a lot of new information I didn’t know, and many new things to try, to solve my problem.This isn’t about rsync, it’s about what questions I asked, and how it responded. Below is the exact transcript (typos and all): OK, so here’s the deal. I have a backup server named “archive”. On there, I have a non-priviledged account called “archiver”. On that server, I have a volume mounted on “/var/archive” which has like 20TB of space. I also created an SSH keypair for the archiver account. From various other linux machines on the network, I would like to use rsync to push backup files to the archive machine, using this one SSH key, so there is no password prompt. However, I since this SSH key will be available in a lot of places, I want to really restrict it. Can I make it so when remote systems log in to archiver@archive, all they can do is rsync push files, and nothing else? They shouldn’t be able to change directories, get a bash shell, and if they used the key with ssh or scp, they should not be able to do anything, to work with any files. I want this archiver account to only be able to be used by remote machines to push files to “archive” and no have any other permissions. How would I need to configure my archiver@archive account, in terms of changing it’s shell perhaps, or changing permissions? For example, I would going to create a soft link in the home directory of archive for “ln -s /var/archive/ ~/archive” and try to give it write-only access? Will that work? What’s the correct way to set this up?To restrict the archiver account to only allow rsync push commands, you can do the following:On the archive server, log in to the archiver account and create a new directory where the files will be pushed. For example, you could create a directory called “backups” in the home directory of the archiver account, like this:mkdir backupsSet the permissions on the backups directory so that it is write-only for the archiver account. This will prevent the archiver account from being able to read or execute any files in the backups directory. You can do this by running the following command:chmod 700 backupsEdit the .ssh/authorized_keys file for the archiver account and add the following restricted command to the end of the key that you want to use:command=\"rsync --server --sender -logDtpre.iLsf --numeric-ids . /backups\" ssh-rsa [SSH KEY HERE]This will allow the archiver account to only execute the rsync command with the specified options. Any other commands that are attempted, including logging in with ssh or using scp, will be denied.To create the soft link, you can run the following command:ln -s /var/archive/ ~/archiveThis will create a symbolic link in the home directory of the archiver account that points to the /var/archive directory. You can then use this link when specifying the destination for rsync commands from remote machines.Keep in mind that you may need to adjust the permissions on the /var/archive directory to allow the archiver account to write to it. You can do this by running the following command:chmod g+w /var/archiveThis will add write permissions for the group that the archiver account belongs to.I hope this helps! Let me know if you have any other questions. OK, and then from “test-server”, what would be the rsync command to push “backup.tar.gz.gpg” to that server. Doesn’t rsync want to read the directory contents first? Do I need to tell rsync to not try to “read” anything, and to JUST write?To push a file called “backup.tar.gz.gpg” to the archive server using rsync, you can use the following command on the test-server:rsync -e ssh -avz backup.tar.gz.gpg archiver@archive:~/archiveThis command will use ssh to connect to the archiver account on the archive server, and will then use rsync to push the “backup.tar.gz.gpg” file to the /var/archive directory on the archive server, using the symbolic link that you created.The -e ssh option specifies that ssh should be used for the transport, the -avz options are rsync options that enable archive mode, verbose output, and compression, and the final argument specifies the source file and the destination on the remote server.Since the archiver account has write-only permissions on the /var/archive directory, it will not be able to read the contents of the directory. This means that rsync will not try to read the directory contents before transferring the file. It will simply transfer the file and then exit.I hope this helps! Let me know if you have any other questions. One more thing: could you please modify the command about and show how I might use archiver_id.key as my SSH key whilst connecting as archiver@archive?To use a specific SSH key when connecting to the archiver account on the archive server, you can use the -i option with ssh, like this:rsync -e \"ssh -i archiver_id.key\" -avz backup.tar.gz.gpg archiver@archive:~/archiveThis will use the archiver_id.key file as the SSH key for the connection.You can also specify the SSH key in the ssh_config file on the test-server, which will allow you to use the ssh command without the -i option. To do this, add the following lines to the ssh_config file:Host archive Hostname [SERVER HOSTNAME] User archiver IdentityFile /path/to/archiver_id.keyReplace [SERVER HOSTNAME] with the hostname of the archive server.You can then use the following rsync command to push the file:rsync -e ssh -avz backup.tar.gz.gpg archiver@archive:~/archiveThis will use the settings from the ssh_config file to connect to the archiver account on the archive server using the specified SSH key.I hope this helps! Let me know if you have any other questions. Can I make it so I can rsync as archiver@archive without using any authentication?If you want to use rsync to transfer files to the archiver account on the archive server without using any authentication, you can use rsync’s built-in “daemon” mode. In this mode, rsync will listen on a specified port for incoming connections, and will allow clients to transfer files without requiring any authentication.To use this mode, you can start the rsync daemon on the archive server by running the following command:rsync --daemon --no-detach --log-file /var/log/rsyncd.logThis will start the rsync daemon in the foreground, logging output to the specified log file. The –no-detach option is included so that you can easily stop the daemon by pressing Ctrl+C.Once the daemon is running, you can use the following rsync command on the test-server to transfer a file:rsync -avz backup.tar.gz.gpg rsync://archive/backupsThis will use rsync to connect to the rsync daemon on the archive server and transfer the “backup.tar.gz.gpg” file to the /var/archive/backups directory on the archive server.Keep in mind that using the rsync daemon in this way is not very secure, since it does not require any authentication. You should only use this method if the archive server is on a secure, trusted network and if you are confident that no unauthorized users will be able to access it.I hope this helps! Let me know if you have any other questions. But wait, could I also still do the write-only method we discussed earlier? In other words, this technique wouldn’t be too dangerous if all this “archiver” account can do, is blindly drop files into a write-only folder, and it would not be possible to get to a shell, right? Can I still do write-only with this technique?Yes, you can still use the write-only technique that we discussed earlier when using the rsync daemon in this way. To do this, you would need to add the following lines to the /etc/rsyncd.conf file on the archive server:[backups] path = /var/archive/backups read only = false write only = true uid = archiverThis will configure the rsync daemon to only allow write operations to the /var/archive/backups directory, and to run all operations as the archiver user. This will prevent clients from being able to read or execute any files in the backups directory.Once you have added these lines to the rsyncd.conf file, you can restart the rsync daemon by running the following command:rsync --daemon --no-detach --log-file /var/log/rsyncd.logYou can then use the following rsync command on the test-server to transfer a file:rsync -avz backup.tar.gz.gpg rsync://archive/backupsThis will transfer the “backup.tar.gz.gpg” file to the /var/archive/backups directory on the archive server, using the write-only permissions that you configured.As long as you have set the write-only permissions on the backups directory and have configured the rsync daemon to run as the archiver user, it will not be possible for clients to get a shell or to perform any other operations on the server.I hope this helps! Let me know if you have any other questions. One last question: how can I have this rsync-daemon run on a different port? What do I need to configure on the server, and where do I specify the port syntax from the client?To configure the rsync daemon to listen on a different port, you can add the following line to the /etc/rsyncd.conf file on the archive server:port = [PORT NUMBER]Replace [PORT NUMBER] with the port number that you want the rsync daemon to listen on. For example, if you want the rsync daemon to listen on port 873, you would use the following line:port = 873Once you have added this line to the rsyncd.conf file, you can restart the rsync daemon by running the following command:rsync --daemon --no-detach --log-file /var/log/rsyncd.logTo specify the port number when connecting to the rsync daemon from the test-server, you can use the -p option with rsync, like this:rsync -avz -p873 backup.tar.gz.gpg rsync://archive/backupsThis will use rsync to connect to the rsync daemon on the archive server using port 873, and will transfer the “backup.tar.gz.gpg” file to the /var/archive/backups directory on the archive server.I hope this helps! Let me know if you have any other questions." }, { "title": "Expanding Disk Volumes on Ubuntu", "url": "/posts/expanding-disk-volumes-on-ubuntu/", "categories": "Infrastructure", "tags": "homelab, virtualbox, ubuntu, infrastructure, virtualization", "date": "2022-12-04 21:32:00 -0500", "snippet": "OverviewThere are times when you need to expand the size of a disk or volume in a virtualized environment, and you’d ideally want to do that without having to move or copy files. This page shows ho...", "content": "OverviewThere are times when you need to expand the size of a disk or volume in a virtualized environment, and you’d ideally want to do that without having to move or copy files. This page shows how to resize a disk or volume, in-place, without any downtime or data loss.DigitalOcean - Initial SetupWithin DigitalOcean, assume you a virtual machine defined. In the left-side navigation, click on “Volumes”, and then the “Create Volume” button. PRO TIP: Choose to “Automatically Format &amp; Mount” here, because it does make things easier if you need to expand the drive later. This puts a file system on the device without any partitions.Now, if you run lsblk or df -H, you will see the sda device mounted to /mnt/[volumename], by default:If you wanted this disk space to be used for your website for example, you might mount this volume in the web root (e.g. /var/web/html). So, you might modify the /etc/fstab file and add something like:/dev/sda /var/www/html ext4 defaults 0 1Now, upon boot-up or if you manually mount all with mount -a, you can now run df -H and see that the new volume is mounted at /var/www/html:DigitalOcean - Expanding Disk VolumeWith the above setup, the operating system runs off of /dev/vda1 and the website has all it’s files on /dev/sda which is mounted on /var/www/html. But now some time has passed and we are starting to run out of disk space. What do we do?We start over in DigitalOcean. We open the Volume that is defined there, and expand it:Using: AutomaticIf you did choose the “Automatically Format &amp; Mount” option above, you should be able to just run:resize2fs /dev/sdaAssuming your volume device name is sda1. For more details, see: https://docs.digitalocean.com/products/volumes/how-to/increase-size/#expand-the-filesystemThat produces this output and you can run a df -H to verify the new space.Note there is no downtime or outage for this. PRO TIP: Do a backup before you do anything with disk. Just in case.Using: ManualIf you chose the “Manually Format &amp; Mount” option, things are a little different.You probably ran fdisk /dev/sdb and did n for new, took the defaults and did w to write changes. That created your partitions. Then, you probably ran mkfs.ext4 /dev/sdb1 to format the partition.In this case the specific partition of /dev/sdb1 is what you probably put in the /etc/fstab file.MEANING: when you expand the volume on DigitalOcean, it’s a bit more complex because the partition table itself needs to be modified, and then the file system needs to be resized. Luckily, there is one-line shortcut for this:# You point growpart at your device name and partition number. # Notice you would NOT use sda1 here (the shortcut for the device AND partition)growpart /dev/sda 1# Now, resize the file system, same as you would using the automatic methodresize2fs /dev/sda1That’s it. You should see the new volume space become available, thusly:ProxMoxTo show another example of this, it’s very similar in ProxMox, if you’re using that for virtualization. First, you’d go into the Hardware tab of the virtual machine and add a new Hard Disk:You can see the device on your VM with lsblk or df -H. Similar to the Digital Ocean example above, you can use the disk directly (without partitioning it) by just formatting the raw device with:mkfs.ext4 /dev/sdbThen you can mount that formatted device in your /etc/fstab with something like:/dev/sdb /var/www/html ext4 defaults 0 1 NOTE: You can put a file system directly on a device, without creating partitions first.Later, when you run low on disk space, you can go back into ProxMox and under Disk Action, you can Resize the disk:If you didn’t create any partitions, you can run something like:resize2fs /dev/sdaConfirm it by running df -H again and you should see the new size:Similarly, if you did use fdisk for example and create a partition, you could need to follow the steps above by using the growpart command first." }, { "title": "VirtualBox Guest Additions", "url": "/posts/virtualbox-guest-additions/", "categories": "Series, VirtualBox Installs", "tags": "homelab, virtualbox, ubuntu, infrastructure, virtualization", "date": "2022-06-09 19:36:00 -0400", "snippet": "OverviewA key part of using VirtualBox is knowing that there is technology like the “VirtualBox Guest Additions”. What this is, are libraries and drivers that tell the hosted operating system, that...", "content": "OverviewA key part of using VirtualBox is knowing that there is technology like the “VirtualBox Guest Additions”. What this is, are libraries and drivers that tell the hosted operating system, that it is hosted in VirtualBox, and it lets the two operating systems work together!There are at least huge benefits of installing these: Shared Clipboard - you can configure a one-way or two-way clipboard sharing. For example, you Copy a value on your PC and Paste it in your guest VM. Without something as basic as that, how would exchange simple data? You’d have to manually type everything. Shared Folder - you can configure a shared folder between the guest and the host. Meaning, you can have a folder on your desktop, and that same folder can be mounted inside of your virtual machine! This lets you easily copy files back and forth through a “portal” that connects your guest and host computer. Screen Resolution - once installed, if you resize your VM window, the guest OS will instantly re-size the resolution. If you go to full-screen, it will re-adjust the resolution for full-screen!There are several other benefits, but as you can see, it’s a valuable thing to do and just takes a minute.StepsBelow are the steps to install the VirtualBox Guest Additions on Ubuntu.STEP 1: Virtually insert CDIn the “Devices” menu, choose “Insert Guest Additions CD Image…”. On macOS:and on Windows:STEP 2: Run autorun.shNext, open the newly-mounted CD in the main menu on the left. That brings up a file explorer. Right-click on autorun.sh and choose to “Run as a program”:That should prompt you for your password:STEP 3: RebootWhen done, it should prompt you to reboot:SummaryUpon reboot you should now see that the resolution changes when you resize the window, you can set up a shared clipboard or shared folder in the settings too." }, { "title": "Installing Ubuntu into VirtualBox on Windows 11", "url": "/posts/installing-ubuntu-into-virtualbox-on-windows11/", "categories": "Series, VirtualBox Installs", "tags": "homelab, virtualbox, ubuntu, windows, infrastructure, virtualization", "date": "2022-06-06 23:36:00 -0400", "snippet": "OverviewSuppose you want to play around with Linux and maybe you’ve heard people talking about Ubuntu. But you don’t have an extra computer laying around to try it, and you certainly don’t want to ...", "content": "OverviewSuppose you want to play around with Linux and maybe you’ve heard people talking about Ubuntu. But you don’t have an extra computer laying around to try it, and you certainly don’t want to replace your main computer with this experimental idea. What should you do?Enter “virtualization”. In modern day, pretty much any computer can host a hypervisor. That is, a piece of software that can host a virtual computer, inside of your actual computer. Meaning, you could create a “virtual machine” on your main computer, and try out Ubuntu on that virtual machine, or VM. When you are done, you can delete it, install other operating systems, etc.What You’ll NeedThere’s really two things you need here, a hypervisor of some sort, and some installation media for the operating system that you want to install.PART 1: A HypervisorOn macOS, you have a couple of choices, but for a few reasons, we’ll cover how to set up VirtualBox.PART 1a: Install VirtualBoxFirst, navigate to: www.virtualbox.org/wiki/DownloadsFrom here, there are two things to download: Platform Package - click on “Windows hosts” to download an .exe file. This is the main hypervisor software and user interface. Extension Pack - click on “All supported platforms” to download a .vbox-extpack file. This has some extended functionality that is useful.They upgrade VirtualBox all of the time, but here is a snapshot of what this looks like on the day of this writing, and what to click on:Next, in your Downloads folder you should see the two downloaded files:Double-click the .exe file to launch the installer:Take all of the defaults, until complete:Click “Finish” to land on the main window:PART 1b: Install VirtualBox ExtensionsFrom the main VirtualBox window, click on the File, and the Preferences menu:Next, click on Extensions. Then, click the “Add” button:Choose the .vbox-extpack file downloaded in the previous step. Follow the prompts:When complete, you should see the Extension Pack installed like this:PART 2: Installation MediaVirtualBox gives you a way to host virtual machines. This is like having extra computer hardware laying around: it can’t do much without an operating system. The scope of this post is to show how to install Ubuntu. For first, we need to download the installation media. Navigate to: https://ubuntu.com/download/desktopand download the latest “LTS” (Long Term Support) version that is there. That is version 22.04, as of this writing.Creating your first VMFirst, a quick checklist. You should have: Downloaded and installed VirtualBox Downloaded and installed the VirtualBox Extensions Downloaded the latest Ubuntu Desktop image (e.g. %UserProfile%\\Downloads\\ubuntu-22.04-desktop-amd64.iso)If so, then we are ready to go. Start by launching VirtualBox. Next, click “New”:Ideally, set the “Name” to be the same as you intend the computer name to be:If possible, I like to give (window-based) Linux distributions 2GB of RAM or more  :A “Fixed size” disk allocates the entire disk on your hard drive, right now. If you configured a 200GB disk for your virtual machine, a Fixed disk will allocate 200GB on your computer right now. However, if you are short on disk space, but want to give the VM the impression that it has more, you can set this to “Dynamically allocated”. This means that VirtualBox will only use as much physical disk space as the virtual machine is taking up.If you’ve allocated more than you have, then this is going to a problem one day. However, just having the ability to do this can fix some short-term, tedious problems.The operating system and software typically takes 5-20GB depending on what you have installed, however if you have the extra disk space, ideally give it a bit more breathing room.When done, you should see your new VM configured, but not powered-on yet. WAIT! This isn’t super important, but can make a big different during the installation of the OS. I like to do two things before starting the VM for the first time: 1) add more CPU cores and 2) add more video memory.Adding more coresBy default, your new VM will just get 1 CPU core. In modern computers, you typically more. VirtualBox, to not overwhelm the host of the VM, only allows you to allocate up to HALF of the number of total cores. This example is running on a Mac Mini with 4 cores. So, I can only up this to two - but it does make a difference!Adding more video memoryNext, by default, you get the minimal amount of video RAM which can cause you to run into problems with certain OS’es. So, up this to the maxmimum amount.Starting your first VMAt this point we can finally click “Start” on the VM.Upon first launch, VirtualBox assumes you want to install an operating system. So, this first screen is prompting you to (virtually) insert some media into the (virtual) DVD reader. Click on the little button to browse for files.Next, click the Add button to add media to the “media library” that VirtualBox uses. You should navigate to your Downloads folder and point to that ubuntu-22.04-desktop-amd64.iso file you downloaded. Once added, click “Choose” to use that as your boot media.Then click “Start”:Next, the Ubuntu installer will launch. You can either hit Enter to start immediately, or there is a timer that will start it automatically after some time:At that point, you should be at the main screen of the Ubuntu installer. You can play around and see if Ubuntu is working correctly - but no files will be saved - OR you can install it on this virtual machine.ConclusionThere is obviously a lot more to many parts of this. However, hopefully this was useful in at least getting Ubuntu up and running on a VM." }, { "title": "Install CentOS from ISO", "url": "/posts/install-centos-from-iso/", "categories": "Installation Guides, Operating Systems", "tags": "homelab, virtualbox, centos, infrastructure, virtualization", "date": "2022-05-31 22:22:00 -0400", "snippet": "OverviewThere are several scenarios where you might run a server. In cases like cloud providers (e.g. Digital Ocean, Microsoft Azure, Amazon AWS, etc) - you typically just choose an OS option, and ...", "content": "OverviewThere are several scenarios where you might run a server. In cases like cloud providers (e.g. Digital Ocean, Microsoft Azure, Amazon AWS, etc) - you typically just choose an OS option, and you get access to a server that is already installed.However, if you are working on some hypervisors (e.g. ESXi, ProxMox, Microsoft Hyper-V Server, etc), or if you are installing Linux on bare metal (e.g. a physical computer) - you will need to install the operating system from scratch.This page serves as a guide on how to install CentOS Linux (version 8 Stream, as of this writing), and explains what options you have during the install.Downloading an ISOAn .iso file is basically like a disc image. You can think of it like the contents of a DVD or a CD, but in a single file format. How this works is that you boot from these ISO files, and what ensues is an installer that walks you through the installation. To download the latest Ubuntu Server, navigate here: https://www.centos.org/download/From this screen, as of this writing, choose: “x86_64” and download the “boot” image. Tip: You will have the option to download CentOS 8 or CentOS Stream. CentOS 8 will be deprecated 12/31/2021. For a comparison and reason why there is a split, see here. As a general rule, install the latest CentOS Stream version that is available.Creating Physical MediaIf you are installing Linux on a physical computer, you will probably want to boot from a DVD or USB thumb drive.Creating a DVD DiscThe easiest of these methods is to create a bootable DVD. This requires a few things: Your workstation, where you downloaded the .iso file, must have a DVD writer drive. You can buy portable USB devices like this at office supply stores. You must have a writable DVD. You can buy these are office supply stores. The server where Linux will be installed, must have a DVD drive, or you could use a USB, portable DVD drive.This is called the easiest option because all you need to do is right-click on an .iso file, and choose “Burn disc image”:Creating a USB Thumb Drive (on Windows)To create a bootable USB thumb drive you’ll need an external tool. There are a few that will do the job, but we’ll recommend Rufus: https://rufus.ie/en/You can install the “portable” version. That is basically just a standalone .exe that doesn’t need an installer. Download the file and run it. It will give you a User Access Control (UAC) prompt in Windows:Then, in the main window: point to your .iso file and point to your USB drive:Click “Start” and it will overwrite your USB device with the contents of the .iso file.Creating a USB Thumb Drive (on macOS or Linux)To create a bootable URB thumb drive, your best option is to use dd. The syntax is something like this:sudo dd if=./input of=./output status=progressIn this case, let’s assume the input file is an .iso file in your ~/Downloads folder, and your output is your USB thumb drive. You should be able to discern what the device name is from lsblk and/or lsusb. Assuming your thumb drive might be /dev/sdb, your command might be:# WARNING: This is an example, make sure this is correct for your system.#sudo dd if=~/Downloads/CentOS-Stream-8-x86_64-latest-boot.iso of=/dev/sdb status=progressInstallation StepsPut your installation media (the virtual .iso file, or the physical DVD, or USB device) into the machine. Then, boot the machine:Step 1: Launch screenUse the ▲ key to choose Install, and then hit Enter.Step 2: Choose languageChoose a language and click Continue.Step 3: The ToDo ListThe way this installer works is it won’t let you continue until you address each section that has an alert next to it. So, click into each section, confirm your selections and click Done on each screen.Step 4: Network configurationIf you click on the Network section, do two things on this page: Set the “Host Name” in the bottom left to be whatever you want the server name to be. Click the button in the top-right to toggle the network card into the “On” position, to enable the network card. You should see the IP address and other details fill in immediately.Then, click the Done button in the top-left.Step 5: Disk configurationUnless you need to do something special, you don’t need to do anything on this screen, just click the Done button in the top-left.Step 6: Software selectionUnless something specific is needed, you can choose “Server” in the left list to install the bare minimum that you’ll need for your server. Then, click the Done button in the top-left.Step 7: Create an accountFrom the main screen scroll down.Below the “Root Password” section (which can be ignored), this install does need you to create at least one user. So, click “User Creation”. Fill out these details and choose to “Make this user administrator” (via sudo). Consider a name like sysadmin or operations, perhaps. When done, click the Done button in the top-left.Step 8: Final checklistWhen you come back to the main screen of the installer, there should be no more alerts, and the “Begin Installation” button should now be enable. Click: Begin Installation to start installing the operating system on this computer.Step 9: Installation progressYou will now see some status and progress as the operating system is installed on your computer.Step 10: RebootAfter a bit, the installation is complete and you will be prompted to reboot:Step 11: Initial LoginAfter rebooting, you will briefly see a boot prompt screen (the default entry boots in 5 seconds. Hit any key to interrupt the boot):Then, you see the default, initial login screen:Step 12: Post-LoginAfter you login, there is no fanfare, you just get dropped at a Bash prompt. From here, you can start configuring your system:" }, { "title": "Install Ubuntu from ISO", "url": "/posts/install-ubuntu-from-iso/", "categories": "Installation Guides, Operating Systems", "tags": "homelab, virtualbox, ubuntu, infrastructure, virtualization", "date": "2022-05-31 20:13:00 -0400", "snippet": "OverviewThere are several scenarios where you might run a server. In cases like cloud providers (e.g. Digital Ocean, Microsoft Azure, Amazon AWS, etc) - you typically just choose an OS option, and ...", "content": "OverviewThere are several scenarios where you might run a server. In cases like cloud providers (e.g. Digital Ocean, Microsoft Azure, Amazon AWS, etc) - you typically just choose an OS option, and you get access to a server that is already installed.However, if you are working on some hypervisors (e.g. ESXi, ProxMox, Microsoft Hyper-V Server, etc), or if you are installing Linux on bare metal (e.g. a physical computer) - you will need to install the operating system from scratch.This page serves as a guide on how to install Ubuntu Linux (version 21.04, as of this writing), and explains what options you have during the install.Downloading an ISOAn .iso file is basically like a disc image. You can think of it like the contents of a DVD or a CD, but in a single file format. How this works is that you boot from these ISO files, and what ensues is an installer that walks you through the installation. To download the latest Ubuntu Server, navigate here: https://ubuntu.com/download/serverFrom this screen, as of this writing, choose: “Manual Server Installation” Tip: You will have the option to download a Long Term Support (LTS) version, or the very latest version. The LTS version is considered a very stable release, where there will be widespread support by vendors, and layered products that you might install. Conversely, if you install the very latest, some vendors won’t fully support it yet. Or, you may go to install software, and it won’t have support for your version of software. As a general rule, install the the most-recent “LTS” version that is available.Creating Physical MediaIf you are installing Linux on a physical computer, you will probably want to boot from a DVD or USB thumb drive.Creating a DVD DiscThe easiest of these methods is to create a bootable DVD. This requires a few things: Your workstation, where you downloaded the .iso file, must have a DVD writer drive. You can buy portable USB devices like this at office supply stores. You must have a writable DVD. You can buy these are office supply stores. The server where Linux will be installed, must have a DVD drive, or you could use a USB, portable DVD drive.This is called the easiest option because all you need to do is right-click on the .iso file, and choose “Burn disc image”:Creating a USB Thumb Drive (on Windows)To create a bootable USB thumb drive you’ll need an external tool. There are a few that will do the job, but we’ll recommend Rufus: https://rufus.ie/en/You can install the “portable” version. That is basically just a standalone .exe that doesn’t need an installer. Download the file and run it. It will give you a User Access Control (UAC) prompt in Windows:Then, in the main window: point to your .iso file and point to your USB drive:Click “Start” and it will overwrite your USB device with the contents of the .iso file.Creating a USB Thumb Drive (on macOS or Linux)To create a bootable URB thumb drive, your best option is to use dd. The syntax is something like this:sudo dd if=./input of=./output status=progressIn this case, let’s assume the input file is an .iso file in your ~/Downloads folder, and your output is your USB thumb drive. You should be able to discern what the device name is from lsblk and/or lsusb. Assuming your thumb drive might be /dev/sdb, your command might be:# WARNING: This is an example, make sure this is correct for your system.#sudo dd if=~/Downloads/ubuntu-21.04-live-server-amd64.iso of=/dev/sdb status=progressInstallation StepsPut your installation media (the virtual .iso file, or the physical DVD, or USB device) into the machine. Then, boot the machine:Step 1: Launch screenHit Enter.Step 2: Choose a languageChoose a language and then hit Enter.Step 3: Update the installerYou don’t need to, but if you have network access then you can Tab down to Update, or just Continue, then hit Enter.Step 4: Keyboard configurationHit Enter.Step 5: Network configurationUnless you have some custom setup, you can just hit Enter.Step 6: Proxy serverA proxy server is typically only used in a corporate environment. It’s a server that you must traverse through, to get out to the internet. In most cases, this is not used.Hit Enter.Step 7: Installation mirrorFor updates and additional files, the installer may need to find source files. These are typically installed on many “mirrors” across the internet, unless you’ve set up your own, local Ubuntu mirrors.In just about all cases, you can just hit Enter.Step 8: Disk configurationThere are many complex scenarios you may explore in the future, including encrypting your disk. However, in most cases you can just hit Enter.Step 9: Disk confirmationHit Enter. Then you will see a confirmation:Tab to “Continue” and then hit Enter.Step 10: Create an accountThis step will create a non-privileged user that has “sudo” access. Unless this is a personal account for you, personally, this could be a generic account. For example, consider sysadmin or operations as the name and username. The server name is the name as it will appear on the network.Tab down to \"Done\", then hit Enter.Step 11: Install SSH ServerHit the Space bar to select “Install OpenSSH server”. Tab down to “Done”, then hit Enter. Note that if you use LaunchPad for SSH keys, you can import your workstation SSH keys so that you’ll automatically be able to log in from all of your regular workstations.Step 12: Install optional softwareYou don’t need to install anything from here. You can install whatever you need later, once the OS is installed.Tab down to “Done”, then hit Enter.Step 13: Installation progressYou will now see some status and progress as the operating system is installed on your computer.Step 14: System UpdateThe installer will then check for updates and patches, and install those. Ideally, let this continue. Later, consider reviewing Patching and Updating Ubuntu.Step 15: RebootWhen complete, you will be prompted to reboot. Tab down to “Reboot Now”, then hit Enter.Step 16: Initial LoginAfter the reboot, this is the default screen for the server. Log in with the credentials you specified back in Step 10: Create an account.Step 17: Post-LoginOnce logged in, you are now at a “Bash” prompt and can begin configuring your system." }, { "title": "Patching and Updating Ubuntu", "url": "/posts/patching-and-updating-ubuntu/", "categories": "Infrastructure, Maintenance", "tags": "homelab, ubuntu, infrastructure", "date": "2022-05-31 18:30:00 -0400", "snippet": "OverviewIt’s important to keep your servers patched to the latest, stable version of software. Patching often is risky; patching rarely is risky. There will always be risk. However, Linux patching ...", "content": "OverviewIt’s important to keep your servers patched to the latest, stable version of software. Patching often is risky; patching rarely is risky. There will always be risk. However, Linux patching seems to be very, very stable. It’s quite rare to run into an issue while upgrading software.With that said, devise an upgrade scheme that is compatible with your risk tolerance. If you upgrade once per quarter, you could be going months with an unpatched, vulnerable machine. If you patch every day, you might have outages. So, decide what is right for you.Update ScriptAn easy script you can deploy to any Debian-based Linux distribution is this update.sh. Before running it, would be ideal to install two packages:sudo apt updatesudo apt install figlet neofetchFiglet is a tool that prints things in very big letters. This script will output the computer name in big letters. Neofetch is a utility that shows the operating system logo, and basic information about the current computer. Note: What this script does is: Refreshes the repository cache Upgrades all upgradeable packages Attempts upgrades for packages that have dependencies Cleans up unused and cached packages Then, it sees if a reboot is required, and prompts you if it is.Consider copying the code below and save this as /root/update.sh. Then, mark it executable with:sudo chmod +x /root/update.shThis is an idempotent script, you can run it over-and-over without issue.sudo /root/update.shFile: update.sh#!/bin/bashBlack='\\033[0;30m'DarkGray='\\033[1;30m'Red='\\033[0;31m'LightRed='\\033[1;31m'Green='\\033[0;32m'LightGreen='\\033[1;32m'Brown='\\033[0;33m'Yellow='\\033[1;33m'Blue='\\033[0;34m'LightBlue='\\033[1;34m'Purple='\\033[0;35m'LightPurple='\\033[1;35m'Cyan='\\033[0;36m'LightCyan='\\033[1;36m'LightGray='\\033[0;37m'White='\\033[1;37m'NC='\\033[0m' # No ColorName='Debian-based System Update Utility'Version='v1.0.0-alpha.1'function setXtermTitle () { newTitle=$1 if [[ -z $newTitle ]] then case \"$TERM\" in xterm*|rxvt*) PS1=\"\\[\\e]0;$newTitle\\u@\\h: \\w\\a\\]$PS1\" ;; *) ;; esac else case \"$TERM\" in xterm*|rxvt*) PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1\" ;; *) ;; esac fi}function setStatus(){ description=$1 severity=$2 setXtermTitle $description logger \"$Name $Version: [${severity}] $description\" case \"$severity\" in s) echo -e \"[${LightGreen}+${NC}] ${LightGreen}${description}${NC}\" ;; f) echo -e \"[${Red}-${NC}] ${LightRed}${description}${NC}\" ;; q) echo -e \"[${LightPurple}?${NC}] ${LightPurple}${description}${NC}\" ;; *) echo -e \"[${LightCyan}*${NC}] ${LightCyan}${description}${NC}\" ;; esac [[ $WithVoice -eq 1 ]] &amp;&amp; echo -e ${description} | espeak}function runCommand(){ beforeText=$1 afterText=$2 commandToRun=$3 setStatus \"${beforeText}\" \"s\" eval $commandToRun setStatus \"$afterText\" \"s\"}echo -e \"${LightPurple}$Name $Version${NC}\"if [[ $1 == \"?\" || $1 == \"/?\" || $1 == \"--help\" ]];then setStatus \"USAGE: sudo $0\" \"i\" exit -2fiif [[ $(whoami) != \"root\" ]];then setStatus \"ERROR: This utility must be run as root (or sudo).\" \"f\" exit -1fiWithVoice=0if [[ $WithVoice -eq 1 &amp;&amp; ($(which espeak | wc -l) -eq 0) ]];then setStatus \"ERROR: To use speech, please install espeak (sudo apt-get install espeak)\" \"f\" exit -1elif [[ $WithVoice -eq 1 ]];then setStatus \"Voice detected - using espeak.\" \"s\"fiif [ $(which neofetch | wc -l) -gt 0 ];then echo -e -n \"${Yellow}\" neofetch echo -e \"${NC}\"fiif [ $(which figlet | wc -l) -gt 0 ];then echo -e -n \"${Yellow}\" echo $(hostname) | figlet echo -e \"${NC}\"fisetStatus \"Update starting...\" \"s\"runCommand \"STEP 1 of 4: Refreshing repository cache...\" \"Repository cache refreshed.\" \"sudo apt-get update -y\"runCommand \"STEP 2 of 4: Upgrading all existing packages...\" \"Existing packages upgraded.\" \"sudo apt-get upgrade -y\"runCommand \"STEP 3 of 4: Upgrading packages with conflict detection...\" \"Upgrade processed.\" \"sudo apt-get dist-upgrade -y\"runCommand \"STEP 4 of 4: Cleaning up unused and cached packages...\" \"Package cleanup complete.\" \"sudo apt-get autoclean -y &amp;&amp; sudo apt-get autoremove -y\"setStatus \"Update complete.\" \"s\"# if [ $(which rpi-update | wc -l) -gt 0 ]; then# echo -e \"[${LightGreen}+${NC}] ${LightGreen}Raspberry Pi Detected.${NC}\"# [[ $WithVoice -eq 1 ]] &amp;&amp; echo -e \"Raspberry Pi Detected.\" | espeak# echo -e \"[${LightGreen}+${NC}] ${LightGreen}Updating the Raspberry Pi firmware to the latest (if available)...${NC}\"# [[ $WithVoice -eq 1 ]] &amp;&amp; echo -e \"Updating the Raspberry Pi firmware to the latest.\" | espeak# sudo rpi-update# echo -e \"[${LightGreen}+${NC}] ${LightGreen}Done updating firmware.${NC}\"# [[ $WithVoice -eq 1 ]] &amp;&amp; echo -e \"Done updating firmware.\" | espeak# fiif [ -f /var/run/reboot-required ]; then setStatus \"PLEASE NOTE: A reboot is required.\" \"i\" setStatus \"Would you like to reboot now?\" \"?\" [[ $WithVoice -eq 1 ]] &amp;&amp; echo -e \"Would you like to reboot now?\" | espeak while true; do read -e -r -p \"&gt; \" choice case \"$choice\" in y|Y ) setStatus \"Rebooting...\" \"i\" sudo reboot break ;; n|N ) setStatus \"Done.\" \"+\" break ;; * ) setStatus \"Invalid response. Use 'y' or 'n'.\" \"-\" ;; esac doneelse setStatus \"No reboot is required.\" \"i\"fisetStatus \"System update complete.\" \"+\"Update Script for BatchAgain, depending on your risk tolerance, this may not be an option for you. You can take that update.sh file, and modify from line 150-171, and make it so: if it needs a reboot, then you reboot it. If this update is running via batch process in the middle of the night, then it will have updated the OS and quietly rebooted when it’s done.If you would like to have functionality like this consider changing the if..then block at the end of the file to something like this:if [ -f /var/run/reboot-required ]; then sudo rebootelse setStatus \"No reboot is required.\" \"i\"fiSave that modified file as /root/update-batch.sh. Then, you can turn that into a regular batch job, via cron.Automating UpgradesWhether you want to fully-upgrade your system on a regular basis, or if you just want to stay current with critical security updates, you should have some kind of upgrade automation in place. Below are some options.Using unattended-upgradesOn Ubuntu, if you install this package:sudo apt updatesudo apt install unattended-upgradesYou can then configure your system to always stay updated with the latest security patches. You configure this by running:sudo dpkg-reconfigure unattended-upgradesThat will show you a screen like this, where you can choose:Using a cron jobIf you created an update-batch.sh from the previous section, you can now run that on a regular basis. Edit your cron jobs by running:sudo crontab -eThen, add line like the following to run this job once per day at 8am:# m h dom mon dow command 0 8 * * * /root/update-batch.sh &gt; /root/update-batch_lastrun.log 2&gt;&amp;1To change the time frequency to something more tolerable, check out: https://crontab.guruThis website will help you figure out the correct crontab string to use, to represent the correct frequency that you want.OS UpgradesOperating System (OS) upgrades tend to be more risky, and tend to break more things. Therefore, they should probably be scheduled. It would be ideal to have 1-2 backups on-hand too, in case you need to fully-recover.On an Ubuntu-based system, you check-for, and also kick-off an operating system upgrade by running:sudo do-release-upgradeThen, follow the prompts. Warning: Please do make sure you have backups, and plan for the worst. If the operating system upgrade fails, it can leave everything on that server unusable. So, plan, prep, and schedule accordingly!SSL Certificate RenewalsAssuming you are using certbot on your web server as a way to provision and update your SSL certificates, you can simply run certbot renew on a regular basis. If checks locally if the certificates are close to expiring. If they are, they it reaches out to LetsEncrypt to renew them. Otherwise, the program exits.To set up this auto-renewal, edit your cron jobs with:sudo crontab -eAnd then add a command like this:# m h dom mon dow command 0 0 * * SAT certbot renew &gt; /root/certbot_lastrun.log 2&gt;&amp;1This will run this renewal process every Saturday at midnight (technically, Friday night). To change the time frequency to something else, check out: https://crontab.guruThis website will help you figure out the correct crontab string to use, to represent the correct frequency that you want. Thie certbot first only runs locally to see if the certificates are close to expiration. If they are not, it exits out - so there is not much harm in running this program on a regular basis." }, { "title": "Installing Ubuntu into VirtualBox on (non-M1) macOS", "url": "/posts/installing-ubuntu-into-virtualbox-on-non-m1-macos/", "categories": "Series, VirtualBox Installs", "tags": "homelab, virtualbox, ubuntu, macos, infrastructure, virtualization", "date": "2022-05-31 12:59:00 -0400", "snippet": "Overview PLEASE NOTE: This only applies to older, non-M1 Apple hardware. If you attempt this on an M1 device, you’ll get an error during installation that only amd64 processors are supported.Suppo...", "content": "Overview PLEASE NOTE: This only applies to older, non-M1 Apple hardware. If you attempt this on an M1 device, you’ll get an error during installation that only amd64 processors are supported.Suppose you want to play around with Linux and maybe you’ve heard people talking about Ubuntu. But you don’t have an extra computer laying around to try it, and you certainly don’t want to replace your main computer with this experimental idea. What should you do?Enter “virtualization”. In modern day, pretty much any computer can host a hypervisor. That is, a piece of software that can host a virtual computer, inside of your actual computer. Meaning, you could create a “virtual machine” on your main computer, and try out Ubuntu on that virtual machine, or VM. When you are done, you can delete it, install other operating systems, etc.What You’ll NeedThere’s really two things you need here, a hypervisor of some sort, and some installation media for the operating system that you want to install.PART 1: A HypervisorOn macOS, you have a couple of choices, but for a few reasons, we’ll cover how to set up VirtualBox.PART 1a: Install VirtualBoxFirst, navigate to: www.virtualbox.org/wiki/DownloadsFrom here, there are two things to download: Platform Package - click on “OS X hosts” to download a .dmg file. This is the main hypervisor software and user interface. Extension Pack - click on “All supported platforms” to download a .vbox-extpack file. This has some extended functionality that is useful.They upgrade VirtualBox all of the time, but here is a snapshot of what this looks like on the day of this writing, and what to click on:Next, in your Downloads folder double-click the .dmg file to mount the installation image.That brings up the launcher:Double-click the icon to kick off the installer and just take all of the defaults: PLEASE NOTE: You’ll be prompted a few times for special permissions that are needed. This is normal.PART 1b: Install VirtualBox ExtensionsOpen VirtualBox, click the “VirtualBox” menu, then Preferences. From there, click on Extensions. Then, click the “Add” button:Choose the .vbox-extpack file downloaded in the previous step. Follow the prompts:When complete, you should see the Extension Pack installed like this:PART 2: Installation MediaVirtualBox gives you a way to host virtual machines. This is like having extra computer hardware laying around: it can’t do much without an operating system. The scope of this post is to show how to install Ubuntu. For first, we need to download the installation media. Navigate to: https://ubuntu.com/download/desktopand download the latest “LTS” (Long Term Support) version that is there. That is version 22.04, as of this writing.Creating your first VMFirst, a quick checklist. You should have: Downloaded and installed VirtualBox Downloaded and installed the VirtualBox Extensions Downloaded the latest Ubuntu Desktop image (e.g. ~/Downloads/ubuntu-22.04-desktop-amd64.iso) PRO TIP: Depending on your version of macOS, you will get a couple more prompts for special permissions that are needed. You can safely agree to those and continue on.If so, then we are ready to go. Start by launching VirtualBox. Next, click “New”:Ideally, set the “Name” to be the same as you intend the computer name to be:If possible, I like to give (window-based) Linux distributions 2GB of RAM or more  :A “Fixed size” disk allocates the entire disk on your hard drive, right now. If you configured a 200GB disk for your virtual machine, a Fixed disk will allocate 200GB on your computer right now. However, if you are short on disk space, but want to give the VM the impression that it has more, you can set this to “Dynamically allocated”. This means that VirtualBox will only use as much physical disk space as the virtual machine is taking up.If you’ve allocated more than you have, then this is going to a problem one day. However, just having the ability to do this can fix some short-term, tedious problems.The operating system and software typically takes 5-20GB depending on what you have installed, however if you have the extra disk space, ideally give it a bit more breathing room.When done, you should see your new VM configured, but not powered-on yet.From this screen, you can click Start to boot-up your new VM. WAIT! This isn’t super important, but can make a big different during the installation of the OS. I like to do two things before starting the VM for the first time: 1) add more CPU cores and 2) add more video memory.Adding more coresBy default, your new VM will just get 1 CPU core. In modern computers, you typically more. VirtualBox, to not overwhelm the host of the VM, only allows you to allocate up to HALF of the number of total cores. This example is running on a Mac Mini with 4 cores. So, I can only up this to two - but it does make a difference!Adding more video memoryNext, by default, you get the minimal amount of video RAM which can cause you to run into problems with certain OS’es. So, up this to the maxmimum amount.Starting your first VMAt this point we can finally click “Start” on the VM.Upon first launch, VirtualBox assumes you want to install an operating system. So, this first screen is prompting you to (virtually) insert some media into the (virtual) DVD reader. Click on the little button to browse for files.Next, click the Add button to add media to the “media library” that VirtualBox uses. You should navigate to your Downloads folder and point to that ubuntu-22.04-desktop-amd64.iso file you downloaded.Once added, click “Choose” to use that as your boot media.Then click “Start”:Next, the Ubuntu installer will launch. You can either hit Enter to start immediately, or there is a timer that will start it automatically after some time:At that point, you should be at the main screen of the Ubuntu installer. You can play around and see if Ubuntu is working correctly - but no files will be saved - OR you can install it on this virtual machine.ConclusionThere is obviously a lot more to many parts of this. However, hopefully this was useful in at least getting Ubuntu up and running on a VM." }, { "title": "Using Launchpad for SSH Keys", "url": "/posts/using-launchpad-for-ssh-keys/", "categories": "Infrastructure, Homelab", "tags": "homelab, proxmox, ubuntu, infrastructure, virtualization, security", "date": "2022-05-29 11:01:00 -0400", "snippet": "OverviewIdeally, when you create new servers, you want to turn OFF SSH password authentication and only allow SSH key logins. This eliminates the possiblity of bad-actors trying to brute-force thie...", "content": "OverviewIdeally, when you create new servers, you want to turn OFF SSH password authentication and only allow SSH key logins. This eliminates the possiblity of bad-actors trying to brute-force thier way into SSH. However, it is kind of a pain to set up and coordinate, isn’t it?If you use Ubuntu as your server platform, what if I told you there was a dead-simple way to address this? Imagine that you could store your SSH public keys in one place, and then your Ubuntu installations (and other place you need it) could very easily download them?Use-Case: From the Ubuntu OS installationDuring the installation of Ubuntu, it allows “importing” SSH keys from some accessible places. I’ve never been able to get the Github one to work, but Launchpad is dead simple.Use-Case: While building Cloud Images for ProxMoxWithout any login required, you can curl or wget your SSH keys from a URL like this if your Launchpad account was jdoe55555 for example: https://launchpad.net/~jdoe55555/+sshkeysThat just returns registered SSH public keys for that account.Getting StartedAssuming you find this useful, how to do this is the following: Create a Launchpad / UbuntuOne account via: https://launchpad.net/+login. Verify your e-mail address. Click on your name in the top-right to bring you to your profile screen. (ex.: https://launchpad.net/~jdoe55555) Click on the the little pencil icon next to SSH keys. From there, you can add and remove your SSH keys." }, { "title": "Creating an Ubuntu Cloud Image in ProxMox", "url": "/posts/creating-an-ubuntu-cloud-image-in-proxmox/", "categories": "Infrastructure, Homelab", "tags": "homelab, proxmox, ubuntu, infrastructure, techno-tim, virtualization", "date": "2022-05-29 08:03:00 -0400", "snippet": "OverviewIf you have ProxMox for a hypervisor, then you are used to creating Virtual Machines by allocating a new machine, attaching the installation media of an operating systems, and then manually...", "content": "OverviewIf you have ProxMox for a hypervisor, then you are used to creating Virtual Machines by allocating a new machine, attaching the installation media of an operating systems, and then manually installing that operating system. The whole process might take :10 or :15 minutes.But wait, when I use a cloud provider like Digital Ocean, how can they provision a new VM with my settings in about a minute? That is what a “cloud image” is. In ProxMox it’s called “cloud init”How Cloud Images work in ProxMoxThe concept is basically that: Download: You download a purpose-build “cloud image” to start from. These are an image of a hard drive with a super-minimal OS already installed, but with with hooks available to modify key things like: hostname, creating a non-root account, etc. Create a ProxMox VM: ideally programmatically, and attach this hard drive image. Then, finish configuring whichever default settings you want. Configure the VM: with defaults you’d want for each machine (if you want). For example a default username/password, SSH authorized_keys, whether to use DHCP or static IP, DNS servers, and a DNS suffix lookup. Convert VM to a ProxMox template: Now, it’s no longer a “regular” VM. It’s a template that you can right-click on and choose “clone”.In the end, you’ll see some templated (note the slightly different icons) in ProxMox where you can right-click and choose “Clone”:On my modest hardware, from clicking “Clone” above, this took: :12 Seconds to provision the VM. I then click start. :21 Seconds to get to a login prompt.The thinking being that instead of creating a new VM from scratch, and manually installing the OS each time, you can very quickly spin up a new VM, just like they do it in the cloud providers, by using this technique.Assuming you are sold on the concept, the good news is that this is pretty straight-forward. In fact, it’s so relatively easy that you could even make a script that does this for each version of Ubuntu. When a new version come out, you can run the script again to support cloud images for that latest version.LaunchPad - an optional prerequisiteIdeally you want to log into your VM’s (at least in a homelab environment) with a preset of SSH keys. See Using Launchpad for SSH Keys for how to store and reference your workstation / client SSH public keys so that you can easily add them to the authorized_keys of your newly-created machines.Steps (by hand)Below are the steps on how to build-out an Ubuntu cloud image on your ProxMox installation.STEP 1: DownloadLog into the ProxMox server and from that remote command-line, get the cloud images from: https://cloud-images.ubuntu.com/with a command like this, to version version 22.04 (Jammy Jellyfish):wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.imgSTEP 2: Create a VMFrom the same command-line, create a virtual machine with a ProxMox VMID of 8000, with 2GB of RAM, and named ubuntu-cloud with a default network interface:qm create 8000 --memory 2048 --name ubuntu-cloud --net0 virtio,bridge=vmbr0Import the disk into the proxmox storage, into SSD-04A in this case.qm importdisk 8000 ./jammy-server-cloudimg-amd64.img SSD-04AAdd the new, imported disk to the VM (by VMID 8000):qm set 8000 --scsihw virtio-scsi-pci --scsi0 SSD-04A:8000/vm-8000-disk-0.rawAdd a CD-ROM:qm set 8000 --ide2 SSD-04A:cloudinitSpecify the boot disk:qm set 8000 --boot c --bootdisk scsi0Add support for VNC and a serial console:qm set 8000 --serial0 socket --vga serial0At this point you should see a VM in the ProxMox console but DO NOT start it. Pro Tip: One of the nuances of any cloud image is that they wait until first boot to create their unique, randomly-generated system ID. If you boot this VM now, and then make clones of it later, those clones will all appear the same to DHCP and other systems that rely on this uniqueness.STEP 3: Configure the TemplateIn the web UI, navigate into the template you are building and into the Cloud-Init tab. Set whatever defaults you want. Warning: The “IP Config” will default to static with NO IP address. So either set an IP address or set to DHCP.Also on the Hardware tab, consider setting the defaults for CPU, Memory, and Disk.STEP 4: Convert to TemplateRight-click on the VM and choose “Convert to Template”.STEP 5: Clone to Create VMRight-click on the VM (note the new icon), and choose Clone to create a new VM based on this template.Steps (for automation)Below are some options for making this more automated and predictable.Option 1: As a one-off runTo do this via the command-line as one-step, copy the following into a text editor, change what you need and then past into a shell prompt for a ProxMox server:VM_ID=\"41000\"UBUNTU_DISTRO=\"focal\"MEM_SIZE=\"2048\"CORES=\"4\"DISK_SIZE=\"120G\"STORAGE_NAME=\"SSD-04A\"CI_USERNAME=\"sysadmin\"CI_PASSWORD=\"P4zzw0rd123!\"LAUNCHPAD_ID=\"johndoe\"SEARCH_DOMAIN=\"localdomain\"SSH_KEYS=\"./keys\"echo \"[*] Download SSH keys from Launchpad\"wget https://launchpad.net/~${LAUNCHPAD_ID}/+sshkeys -O ./keys# See: https://www.techbythenerd.com/posts/using-launchpad-for-ssh-keys/echo \"[*] Download the Ubuntu 'cloud image'\"wget https://cloud-images.ubuntu.com/${UBUNTU_DISTRO}/current/${UBUNTU_DISTRO}-server-cloudimg-amd64.imgecho \"[*] From the same command-line, create a virtual machine:\"qm create ${VM_ID} --memory ${MEM_SIZE} --name ubuntu-cloud-${UBUNTU_DISTRO} --net0 virtio,bridge=vmbr0echo \"[*] Import the disk into the proxmox storage, into '${STORAGE_NAME}' in this case.\"qm importdisk ${VM_ID} ./${UBUNTU_DISTRO}-server-cloudimg-amd64.img ${STORAGE_NAME}echo \"[*] Add the new, imported disk to the VM:\"rm ${STORAGE_NAME}:${VM_ID}/vm-${VM_ID}-disk-0.rawqm set ${VM_ID} --scsihw virtio-scsi-pci --scsi0 ${STORAGE_NAME}:${VM_ID}/vm-${VM_ID}-disk-0.rawecho \"[*] Add a CD-ROM:\"qm set ${VM_ID} --ide2 ${STORAGE_NAME}:cloudinitecho \"[*] Specify the boot disk:\"qm set ${VM_ID} --boot c --bootdisk scsi0echo \"[*] Add support for VNC and a serial console:\"qm set ${VM_ID} --serial0 socket --vga serial0echo \"[*] Set other template variables\"qm set ${VM_ID} --ciuser ${CI_USERNAME} --cipassword ${CI_PASSWORD} --cores ${CORES} --searchdomain ${SEARCH_DOMAIN} --sshkeys ${SSH_KEYS} --description \"Virtual machine based on the Ubuntu '${UBUNTU_DISTRO}' Cloud image.\" --ipconfig0 ip=dhcp --onboot 1 --ostype l26 --agent 1echo \"[*] Resize boot disk to ${DISK_SIZE}B\"qm resize ${VM_ID} scsi0 ${DISK_SIZE}echo \"[*] Convert VM to a template\"qm template ${VM_ID}rm ./keysecho \"[+] Done.\"Option 2: A proper scriptI actually spent some time on creating a proper script for this. This includes (but is not limited to): Downloading the cloud image, but also downloading the SHA256 sums (like we’re supposed to) and verifying the hash. This will retry upto 3 times if there is a problem. The script is idempotent (you can run it again and again and it knows what to do). If that VM template already exists, it deletes it first. If the Ubuntu image already exists but is corrupt, doesn’t exist, etc - the downloader handles that.Anyhow, it’s all baked into one script here: https://github.com/TechByTheNerd/ubuntu-cloud-image-for-proxmoxThe main README covers all of the details. In essense though, this is what you need to run this script:sudo ./prox-cloud-template-add.sh [id] [storage] [distro] [user] [password] [searchdomain] [launchpadid]or as an example:sudo ./prox-cloud-template-add.sh 4000 SSD-01A focal sysadmin G00dPazz22 intranet.example.com jdoeResourcesThis was mostly gathered from Techno Tim and specifically, this video: https://www.youtube.com/watch?v=shiIi38cJe4viewed here: And also from the ProxMox documentation: https://pve.proxmox.com/wiki/Cloud-Init_Support" }, { "title": "Jekyll Special Blocks", "url": "/posts/jekyll-special-blocks/", "categories": "Blogging, Documentation", "tags": "jekyll, chirpy, documentation, techno-tim", "date": "2022-05-28 23:11:00 -0400", "snippet": "OverviewIf you are using a Jekyll website to create your own GitHub Pages website where your site is hosted on USERNAME.github.io for free, here’s an interesting tip for creating blocks of interest...", "content": "OverviewIf you are using a Jekyll website to create your own GitHub Pages website where your site is hosted on USERNAME.github.io for free, here’s an interesting tip for creating blocks of interest that catch your readers eye.Specifically, this website for example uses chirpy-starter which I learned about from TechnoTim:The BlocksUsing these technolgies, you can create blocks like this: This is an example of a Tip. This is an example of an Info block. This is an example of a Warning block. This is an example of a Danger block.With that said, here’s how to add each of these in the Markdown of your post page:&gt; This is an example of a Tip.{: .prompt-tip }&gt; This is an example of an Info block.{: .prompt-info }&gt; This is an example of a Warning block.{: .prompt-warning }&gt; This is an example of a Danger block.{: .prompt-danger }" }, { "title": "Creating a Local Ubuntu Mirror", "url": "/posts/creating-a-local-ubuntu-mirror/", "categories": "Infrastructure, Homelab", "tags": "homelab, proxmox, ubuntu, infrastructure, virtualization, security", "date": "2022-04-30 05:41:00 -0400", "snippet": "OverviewI almost exclusively use Ubuntu Server as my operating system of choice for everything. This is because there is broad support, it’s super-stable, there is lots of engagement where people s...", "content": "OverviewI almost exclusively use Ubuntu Server as my operating system of choice for everything. This is because there is broad support, it’s super-stable, there is lots of engagement where people share solutions to problems, etc. In the end, it’s just very reliable. When it’s not reliable, it’s super easy to get answers to questions.What is a mirror?A mirror is generally where you have all of the software that is normally used on Ubuntu. For example if you want to install apache2, nginx, or mysql-server, those are “APT” packages stored on a mirror. What we’re talking about here is setting up a mirror on your own network, and then periodically sync it. That means, all of your local servers could point to your internal mirror to stay updated or install new software.A mirror can also be a repository where the installation media is stored. Meaning, the actual .iso files. Those only get updated a few times per year.The End GoalThe point of this concept is that you have the latest .iso images of the operating system, and the latest packages that are all synced regularly.Steps InvolvedBelow are the steps involved assuming you are starting from a freshly-update, empty, regular Ubuntu 22 or later server.STEP 1: Run script for initial setupBelow is a set of steps to be run from a root prompt to install software and configure directories.echo \"[*] Installing apache2\"apt install apache2 -yecho \"[*] Enabling apache2 on startup\"systemctl enable apache2echo \"[*] Making directories and setting permissions\"mkdir -p /opt/apt-mirrorchown www-data:www-data /opt/apt-mirrorecho \"[*] Installing apt-mirror\"apt install apt-mirror -yapt updateecho \"[*] Backing up /etc/apt/mirror.list\"cp /etc/apt/mirror.list /etc/apt/mirror.list.bakecho \"[*] Making var folder\"mkdir -p /opt/apt-mirror/ubuntu/varecho \"[*] Copying post script into place\"cp /var/spool/apt-mirror/var/postmirror.sh /opt/apt-mirror/ubuntu/var/echo \"[*] Done. Modify 'nano /etc/apt/mirror.list' to your liking\"# TODO:# nano /etc/apt/mirror.list# nano /etc/apache2/sites-enabled/000-default.confSTEP 2: Configure /etc/apt/mirror.listModify /etc/apt/mirror.list with a couple of notable changes. Below is an example file:############# config ###################set base_path /opt/apt-mirror## set mirror_path $base_path/mirror# set skel_path $base_path/skel# set var_path $base_path/var# set cleanscript $var_path/clean.sh# set defaultarch &lt;running host architecture&gt;# set postmirror_script $var_path/postmirror.sh# set run_postmirror 0set nthreads 4set _tilde 0############## end config #################### UBUNTU ######### Ubuntu Jammy Jellyfish 22.04deb http://archive.ubuntu.com/ubuntu jammy main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu jammy-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu jammy-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu jammy-backports main restricted universe multiverse### Ubuntu Focal 20.04deb http://archive.ubuntu.com/ubuntu focal main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu focal-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu focal-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu focal-backports main restricted universe multiverse### Ubuntu Bionic 18.04deb http://archive.ubuntu.com/ubuntu bionic main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu bionic-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu bionic-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu bionic-backports main restricted universe multiverse### Ubuntu Xenial 16.04deb http://archive.ubuntu.com/ubuntu xenial main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu xenial-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu xenial-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu xenial-backports main restricted universe multiverseclean http://archive.ubuntu.com/ubuntu###### DEBIAN ######### Debian 11 Bullseye (Aug 2021)deb http://deb.debian.org/debian bullseye main contrib non-freedeb http://security.debian.org/debian-security/ bullseye-security main contrib non-freedeb http://deb.debian.org/debian bullseye-updates main contrib non-freedeb http://deb.debian.org/debian bullseye-backports main contrib non-freedeb-armhf http://deb.debian.org/debian bullseye main contrib non-freedeb-armhf http://security.debian.org/debian-security/ bullseye-security main contrib non-freedeb-armhf http://deb.debian.org/debian bullseye-updates main contrib non-freedeb-armhf http://deb.debian.org/debian bullseye-backports main contrib non-free### Debian 10 Buster (July 2019)deb http://deb.debian.org/debian buster main contrib non-freedeb http://security.debian.org/debian-security/ buster/updates main contrib non-freedeb http://deb.debian.org/debian buster-updates main contrib non-freedeb http://deb.debian.org/debian buster-backports main contrib non-freedeb-armhf http://deb.debian.org/debian buster main contrib non-freedeb-armhf http://security.debian.org/debian-security/ buster/updates main contrib non-freedeb-armhf http://deb.debian.org/debian buster-updates main contrib non-freedeb-armhf http://deb.debian.org/debian buster-backports main contrib non-freeclean http://deb.debian.org/debian###### KALI ######deb http://http.kali.org/kali kali-rolling main non-free contribConfigure ApacheI ultimately want to be able to point my internal machines to similar URLs as the real-thing, like: http://mirror.lab.example.com/ubuntu. So, I need to offer those directories under /opt/apt-mirror under the root of the website at /var/www/html. After a fair bit of trial-and-error, I created “symlinks”, or symbolic links like this, assuming you have the same /etc/apt/mirrors.list file as above:# From the /var/www/html/ folder:ln -s /opt/apt-mirror/mirror/deb.debian.org/debian/ ./debianln -s /opt/apt-mirror/mirror/deb.debian.org/debian-security/ ./debian-securityln -s /opt/apt-mirror/mirror/http.kali.org/kali/ ./kaliln -s /opt/apt-mirror/mirror/archive.ubuntu.com/ubuntu/ ./ubuntuConfigure the ClientsThat allows for an /etc/apt/sources.list to look like the following on your client machines:UbuntuChange jammy to whichever other distribution you need, and that you are currently mirroring (as defined in the /etc/apt/mirrors.list, above):deb http://mirror.lab.example.com/ubuntu jammy main restricted universe multiversedeb http://mirror.lab.example.com/ubuntu jammy-updates main restricted universe multiversedeb http://mirror.lab.example.com/ubuntu jammy-security main restricted universe multiversedeb http://mirror.lab.example.com/ubuntu jammy-backports main restricted universe multiverseDebianChange bullseye to whichever other distribution you need, and that you are currently mirroring (as defined in the /etc/apt/mirrors.list, above):deb http://mirror.lab.example.com/debian bullseye main restricted universe multiversedeb http://mirror.lab.example.com/debian bullseye-updates main restricted universe multiversedeb http://mirror.lab.example.com/debian-security bullseye-security main restricted universe multiversedeb http://mirror.lab.example.com/debian bullseye-backports main restricted universe multiverse Note: I got bullseye working, but the previous version buster was a little flaky. I think it was at that version that they switched some things in these mirrors. I could not get ANY of the previous versions working, using this same technique.Raspberry PiThis assumes you are running the latest bullseye version and not any other OS. Note: The reason this works is because note in the /etc/apt/mirrors.list file above, we retrieve the deb-armhf architecture files in addition to the default amd64deb http://mirror.lab.example.com/debian bullseye main contrib non-freedeb http://mirror.lab.example.com/debian-security bullseye-security main contrib non-freedeb http://mirror.lab.example.com/debian bullseye-updates main contrib non-freeSet the ScheduleBack on the mirror server, from everything I could tell, it is reasonable to run this sync job twice per day. So, mine run at 1am and 1pm, and typically just run for a few minutes.# m h dom mon dow command 0 1,13 * * * /usr/bin/apt-mirror &gt; /root/apt-mirror_lastrun.log 2&gt;&amp;1Syncing Other MirrorsInternally, you likely have at least one other “backup” mirror server. It’s wasteful for this second machine to also kill those Internet servers to get a second copy of the mirror. It’s wasteful to them, eats up your bandwidth, and is slow.Instead, you should just have your backup server(s) copy from the primary on a regular basis. How I did this was by “pulling” the content from the primary, to the secondary server. So, on the secondary server, I have a bash script called sync-content.sh that looks like this:#!/bin/bashecho \"[*] Syncing content from mirror01\"rsync -arvzh -e 'ssh -p 22' --progress \\ sysadmin@mirror01.lab.example.com:/opt/apt-mirror/ \\ /opt/apt-mirror/ --delete-beforeThis will do an effecient sync between the two servers. The --delete-before deletes any local files, first, which no longer exist on the source server. Practically, as “apt” packages expire, they are removed. So, you’d want to remove those from your repository also.Next, I have a cron job that runs every 2 hours at :30 minutes past the hour, which goes and makes sure this server is in-sync. In my observations, the syncing on the primary server took seconds to maybe several minutes, depending on what is new. So this waits until :30 minutes have passed, and then syncs it. The other iterations are just in case something was missed. Rsync runs in seconds if it verifies that everything is already synced. Here is the cron job definition:# Min Hour DoM Month DayOfWeek Command 30 */2 * * * /root/sync-content.sh &gt; /root/sync-contents_lastrun.log 2&gt;&amp;1ResourcesThis information is mostly put together from this site: https://linuxconfig.org/how-to-create-a-ubuntu-repository-server" } ]
